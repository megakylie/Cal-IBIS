---
title: "Step1_DownloadGBIF"
author: "Josie Lesage & Kylie Etter"
date: "10/13/2020"
output: html_document
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = TRUE)

# Setup packages
library(tidyverse) 
library(rgbif) # package to download from gbif https://docs.ropensci.org/rgbif/articles/rgbif.html#get-occurrence-data-from-gbif 
library(usethis) # package recommended to use with rgbif to save GBIF credentials in a .Renviron file so you don't have to enter them in the code with each download query directions: https://docs.ropensci.org/rgbif/articles/gbif_credentials.html
```


# File goal
This file is intended to gather GBIF records for species on the California Channel Islands, which will be used to update the Cal-IBIS repository. **Before getting started**, create a folder for the date at which you are doing the download (for example, "October2024"). You can just copy and rename the "MonthYear" folder in "Cal-IBIS/Data"

The file location should be within your R project and look something like:
>  C:\Users\ketter\OneDrive - Santa Barbara Botanic Garden\gitit_surface\Cal-IBIS-GBIF\Data\October2024"

Capitalization matters here, so be careful and consistent. 

Then, within that folder, make sure there is a  **a "Raw" folder and "GBIFClean Data" folder** -- this is where all of your files will end up.

Finally, hit ctrl+F within this R markdown, and *replace all* of the previous date ("October2024") with the new date, the name of the MonthYear folder you just created.

# Gathering GBIF Data
To begin, we'll gather the data we're interested in from GBIF. We'll download several separate datasets - these will end up as .zip folders in the "Data/GBIF/MonthYear" folder we created, and will need to be unzipped later.

Set up login credentials for GBIF. Run the code and enter the credentials as follows or whatever GBIF login you want to use. 
GBIF_USER="ketter_sbbg"
GBIF_PWD="GBIF4SBBG"
GBIF_EMAIL="ketter@sbbotanicgarden.org"
```{r}
#This opens to .Renviron file 
usethis::edit_r_environ()
```

Define the island polygons to capture all occurrences on the islands. The lists of coordinates form polygons around all the islands and it is pulling all the occurrences within those polygons from any point in time. This code creates two list of polygons (the CA Baja islands and USA CA Channel Islands), with each individual polygon within double parenthesis(()). I had to split into two because it wasn't catching the closing " when it was all together. 
```{r}
#Baja is in this order: Cedros y Natividad (-115.058 27.8699), San Benito (-115.572 28.4047), Guadalupe (-118.265 29.2801), San Jeronimo ((-115.748 29.7948), San Martin (-116.043 30.5660), Todos Santos (-116.724 31.7577), Coronados (-117.236 32.3001)
island_polygons_baja <- "MULTIPOLYGON( ((-115.058 27.8699, -115.079 27.9225, -115.127 27.9553, -115.103 27.9768, -115.085 28.0076, -115.080 28.0787, -115.056 28.1297, -115.054 28.1866, -115.067 28.2291, -115.061 28.2673, -115.075 28.3287, -115.103 28.4003, -115.138 28.4388, -115.190 28.4635, -115.245 28.4629,	-115.296 28.4386, -115.338 28.3900, -115.365 28.3003, -115.353 28.2411, -115.387 28.2010, -115.421 28.1820, -115.443 28.1547, -115.459 28.0889, -115.456 28.0547, -115.439 28.0244, -115.413 28.0018, -115.376 27.9860, -115.337 27.9832, -115.299 27.9546, -115.323 27.9120, -115.320 27.8642, -115.300 27.8337, -115.228 27.7701, -115.161 27.7587, -115.108 27.7734, -115.083 27.7939, -115.067 27.8200, -115.090 27.8420, -115.091 27.8514, -115.058 27.8699)), ((-115.572 28.4047, -115.629 28.4020, -115.674 28.3781, -115.701 28.3343, -115.705 28.2818, -115.685 28.2449, -115.649 28.2187, -115.604 28.2068, -115.522 28.2031, -115.482 28.2193, -115.452 28.2495, -115.437 28.2852, -115.437 28.3242, -115.454 28.3574, -115.491 28.3906,  -115.529 28.4044, -115.572 28.4047)), ((-118.265 29.2801, -118.395 29.2438, -118.451 29.1983, -118.469 29.1501, -118.462 29.1126, -118.465 29.0563, -118.448 29.0227, -118.415 28.9944, -118.415 28.9639, -118.396 28.9051, -118.400 28.8608, -118.393 28.8309, -118.352 28.7786, -118.321 28.7631, -118.289 28.7572, -118.238 28.7661, -118.198 28.7949, -118.134 28.8871, -118.120 28.9596, -118.128 29.0784, -118.169 29.1446, -118.159 29.1858, -118.166 29.2223, -118.206 29.2647, -118.265 29.2801)), ((-116.043 30.5660, -116.081 30.5833, -116.125 30.5870, -116.166 30.5756, -116.202 30.5508, -116.223 30.5177, -116.228 30.4810, -116.216 30.4439, -116.189 30.4146, -116.146 30.3954, -116.103 30.3903, -116.058 30.4014, -116.025 30.4225, -116.040 30.4325, -116.058 30.4715, -116.043 30.5660)), ((-116.724 31.7577, -116.680 31.7786, -116.684 31.8219, -116.699 31.8552, -116.726 31.8804, -116.775 31.9001,  -116.817 31.9032, -116.860 31.8914, -116.894 31.8657, -116.914 31.8280, -116.913 31.7872, -116.894 31.7546,	-116.850 31.7176, -116.809 31.7017, -116.765 31.7011, -116.726 31.7149, -116.753 31.7407, -116.747 31.7568, -116.724 31.7577)), ((-117.236 32.3001, -117.183 32.3140, -117.146 32.3476, -117.133 32.3943, -117.144 32.4462, -117.181 32.4892, -117.251 32.5264, -117.293 32.5363, -117.337 32.5308, -117.373 32.5116, -117.398 32.4824, -117.407 32.4477, -117.400 32.4090, -117.377 32.3760, -117.338 32.3509, -117.308 32.3198, -117.275 32.3050, -117.236 32.3001)), ((-115.748 29.7948, -115.778 29.8235, -115.822 29.8119, -115.822 29.7749, -115.777 29.7538, -115.749 29.7832, -115.748 29.7948)))"

#Channel is in this order: San Clemente (-118.343 32.7261), San Nicolas (-119.537 33.3755), Catalina (-118.610 33.5691), Santa Barbara (-119.032 33.3750), Anacapa, Cruz, Rosa and Miguel (-120.236 34.1001)
island_polygons_channel <- "MULTIPOLYGON(((-118.343 32.7261, -118.291 32.7437, -118.252 32.7828, -118.243 32.8295, -118.263 32.8735, -118.416 32.9937, -118.477 33.0774, -118.515 33.1083, -118.550 33.1211, -118.598 33.1258, -118.670 33.1050, -118.694 33.0844, -118.709 33.0590, -118.711 32.9949, -118.587 32.7994, -118.492 32.7299, -118.462 32.7156, -118.414 32.7107, -118.343 32.7261)), ((-119.537 33.3755, -119.620 33.3617, -119.667 33.3300, -119.686 33.280, -119.669 33.2168, -119.646 33.1876, -119.609 33.1599, -119.532 33.1333, -119.463 33.1248, -119.389 33.1400, -119.356 33.1624, -119.331 33.1991, -119.327 33.2353, -119.340 33.2730, -119.363 33.3033, -119.409 33.3361, -119.491 33.3695, -119.537 33.3755)), ((-118.610 33.5691, -118.654 33.5598, -118.690 33.5354, -118.711 33.5009, -118.712 33.4621, -118.695 33.4261, -118.656 33.3815, -118.596 33.3480, -118.577 33.3020, -118.542 33.2631, -118.488 33.2359, -118.401 33.2286, -118.334 33.2090, -118.277 33.2174, -118.231 33.2435, -118.201 33.2852, -118.199 33.3399, -118.218 33.3824, -118.262 33.4269, -118.289 33.4692, -118.339 33.4976, -118.456 33.5367, -118.501 33.5620, -118.610 33.5691)), ((-119.032 33.3750, -118.989 33.3837, -118.954 33.4045, -118.931 33.4346, -118.920 33.4753, -118.925 33.5151, -118.947 33.5480, -118.983 33.5702, -119.028 33.5792, -119.084 33.5688, -119.119 33.5517, -119.146 33.5211, -119.156 33.4839, -119.143 33.4384, -119.118 33.4043, -119.077 33.3815, -119.032 33.3750)), ((-120.236 34.1001, -120.325 34.1589, -120.364 34.1664, -120.404 34.1616, -120.474 34.1313, -120.533 34.0941, -120.556 34.0522, -120.554 34.0086, -120.528 33.9712, -120.488 33.9477, -120.373 33.9247, -120.317 33.9287, -120.298 33.9173, -120.248 33.8540, -120.171 33.8149, -120.132 33.8048, -120.087 33.8072, -120.011 33.8305, -119.970 33.8516, -119.920 33.8616, -119.887 33.8830, -119.828 33.8699, -119.713 33.8695, -119.628 33.8971, -119.528 33.9098, -119.485 33.9290, -119.436 33.9157, -119.363 33.9154, -119.284 33.9497, -119.261 33.9746, -119.250 34.0053, -119.261 34.0566, -119.304 34.0944, -119.354 34.1072, -119.453 34.1050, -119.514 34.1361, -119.551 34.1453, -119.612 34.1406, -119.658 34.1216, -119.737 34.1473, -119.795 34.1477, -119.838 34.1602, -119.927 34.1675, -119.977 34.1537, -120.013 34.1224, -120.070 34.1271, -120.114 34.1144, -120.155 34.1152, -120.208 34.0996, -120.236 34.1001)))"

```

Run the chunk below, this download will take a while. In 2024 this code pulled over 1 million occurrences, so be patient -- give it at least ~1 hour before coming back and moving on to the next chunk. Josie suggests making a cup of nice tea and enjoying it while tidying your inbox.

The chunk below is long, but will prep your data downloads for everything in the following order:
1. Reptiles
2. Mammals
3. Fungi
4. Arthropods
5. Plants
6. Amphibia
7. Aves
8. Fishes
9. Non-arthro inverts

*KJE note, To describe what the chunk below are doing  it is downloading all the spatial data from GBIF on the Channel Islands (as defined in island_polygons_baja and island_polygons_channel) from the specified taxon. The taxonKey = a number that GBIF has assigned to that taxa, reptiles, fish and non-arthropod inverts needed multiple taxonKeys to capture everything within "Fishes" and "Non-arthro inverts". The format = "DWCA" is the format the data is downloaded in, DarwinCore Archive (which has Raw data, Interpreted data, multimedia links, coordinates and it's a Tab-delimited CSV)

Breakdown of code more: occ_download is a function that defines the parameters for downloading and generates a download on GBIF (under the credentials specified above). the taxonKey defines the taxonomic groups we are pulling, the pred_within defines the geographical space to pull from. occ_download_queue creates a queue of multiple requests let's you kick off any number of requests, while abiding by GBIF rules of 3 concurrent requests per user. It will run the first 3 requests and then start running the next ones as they finish. 

From the rgbif website about occ_download_queue: "Beware
This function is still in development. There's a lot of complexity to this problem. We'll be rolling out fixes and improvements in future versions of the package"... so expect to have to adjust your code with new versions.
```{r prep all data downloads}
all_dl <- occ_download_queue(

# REPTILIA: Reptilies are paraphyletic and the living taxa in our area are turtles (11418144), crocodilians (11492978), squamates (11592253).
occ_download(pred_or(pred("taxonKey", 11592253), pred("taxonKey", 11493978), pred("taxonKey", 11418114)), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA"),

# MAMMALIA
occ_download(pred("taxonKey", 359), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA"),

# FUNGI
occ_download(pred("taxonKey", 5), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA"),

# ARTHROPODA
occ_download(pred("taxonKey", 54), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA"),

# PLANTAE
occ_download(pred("taxonKey", 6), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA"),

# AMPHIBIA
occ_download(pred("taxonKey", 131), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA"),

# AVES
occ_download(pred("taxonKey", 212), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA"),

# FISHES *KJE 2023, Actinoterygii taxon doesn't exist on GBIF anymore, that class apparently contained 95% of all fish, so there was initially a significant drop in records..updated the keys to: subclass Elasmobranchii(121), subclass Holocephali(120), class, Myxini(119), order Coelacanthiformes (765), order Acipenseriformes (1103), order Amiiformes(494), order Anguilliformes(495), order Atheriniformes(496), order Aulopiformes(497), Beryciformes(499), Characiformes(537), Clupeiformes(538), Cypriniformes(1153), Cyprinodontiformes(547), Elopiformes(1162), Esociformes(5488), Gadiformes(549), Gasterosteiformes(550), Gobiesociformes(1163), Lepisosteiformes(1167), Lophiiformes(1305), Ophidiiformes(1308), Osmeriformes(1068), Osteoglossiformes(1069), Perciformes(587), Percopsiformes(1310), Petromyzontiformes(771), Pleuronectiformes(588), Salmoniformes(1313), Scorpaeniformes(590), Siluriformes(708), Syngnathiformes(773), Tetraodontiformes(772)
occ_download(pred_or(pred("taxonKey", 119), pred("taxonKey", 765), pred("taxonKey", 121), pred("taxonKey", 120), pred("taxonKey", 1103), pred("taxonKey", 494), pred("taxonKey", 495), pred("taxonKey", 496), pred("taxonKey", 497), pred("taxonKey", 499), pred("taxonKey", 537), pred("taxonKey", 538), pred("taxonKey", 1153), pred("taxonKey", 547), pred("taxonKey", 1162), pred("taxonKey", 5488), pred("taxonKey", 549), pred("taxonKey", 550), pred("taxonKey", 1163), pred("taxonKey", 1167), pred("taxonKey", 1305), pred("taxonKey", 1308), pred("taxonKey", 1068), pred("taxonKey", 1069), pred("taxonKey", 587), pred("taxonKey", 1310), pred("taxonKey", 771), pred("taxonKey", 588), pred("taxonKey", 1313), pred("taxonKey", 590), pred("taxonKey", 708), pred("taxonKey", 773), pred("taxonKey", 772)), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA"),

# Non-arthropod INVERTS
occ_download(pred_or(pred("taxonKey", 105), pred("taxonKey", 108), pred("taxonKey", 110), pred("taxonKey", 14), pred("taxonKey", 19), pred("taxonKey", 22), pred("taxonKey", 42), pred("taxonKey", 43), pred("taxonKey", 45), pred("taxonKey", 50), pred("taxonKey", 51), pred("taxonKey", 52), pred("taxonKey", 53), pred("taxonKey", 55), pred("taxonKey", 5967454), pred("taxonKey", 5967456), pred("taxonKey", 5967481), pred("taxonKey", 62), pred("taxonKey", 63), pred("taxonKey", 64), pred("taxonKey", 67), pred("taxonKey", 7190138), pred("taxonKey", 74), pred("taxonKey", 75), pred("taxonKey", 76), pred("taxonKey", 7664204), pred("taxonKey", 77), pred("taxonKey", 8173593), pred("taxonKey", 8246594), pred("taxonKey", 8355438), pred("taxonKey", 91), pred("taxonKey", 9238047)), pred_or(pred_within(island_polygons_baja), pred_within(island_polygons_channel)), format="DWCA")
                     )
```

## Downloading zip files
Did you wait at least 1 hour? After an hour check the status on gbif: https://www.gbif.org/user/download just to make sure that no data pulling issue popped up and that the requests are running. (More info and photos are in the Cal-IBISUpdate_Workflow.docx ) *KJE Note it's been taking longer and longer, in October 2024 it took a handful of hours

Once you see 'running 9 of 9 ....succeeded' in the console, run the chunk below. The tibble it produces should show 9 datasets, and should show "succeeded" under "status".

If you get a failure message  Reference the Cal-IBISUpdate_Workflow.docx from troubleshooting insight. 

When the chunk below shows that all data has been prepared successfully, you're ready to move on. 

```{r show download list}
list <- as_tibble(occ_download_list(user = "ketter_sbbg", 
             pwd = "GBIF4SBBG", limit = 9))
#check the results$totalrecords column to confirm an appropriate amount of data was pulled (the lowest amount of recorded will be about 5000 and birds will be the highest around 500,000)
```

You can now download the data! However, we need to make a few changes to the code below:

**BEFORE RUNNING THE CHUNK:** You'll need to change the keys (the long numbers in quotes) to reflect the keys shown by the chunk above - just copy and paste each of those nine below. *KJE note, I copied and pasted from the results$key column in the list dataframe. Do it in reverse order, so copy the bottom one first and put it in the first function below. This is to make sure that they are in the same order as the names, so you can easily name them without having to open up the raw data. After you paste them if the numbers before the dash are in numerically ascending order, it's right!

Also, make sure the date in the file path is correct and that you created the "Raw" folder needed.

Downloading the .zip files by running the code below will also take a small chunk of time -- be patient while the computer obtains all of the info.

```{r}

occ_download_get("0018742-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

occ_download_get("0018743-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

occ_download_get("0018744-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

occ_download_get("0018749-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

occ_download_get("0018751-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

occ_download_get("0018752-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

occ_download_get("0018756-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

occ_download_get("0018759-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

occ_download_get("0020009-241007104925546",
                 overwrite = TRUE,
                 path = "Data/October2024/Raw")

```

Once all 9 zip folders are downloaded, you'll need to rename them for the correct group (i.e Mammals, Fungi, Plants etc) in your computer file browser (meaning this work can't happen in R). You downloaded them in the same order as you queued them, so it's in the order listed below. Although, I like to double check by comparing with the downloads list online:
https://www.gbif.org/user/download Reference the Cal-IBISUpdate_Workflow.docx for further clarification if needed.

The DOI url visible online should line up with the occ_download_list chunk above, and you'll be able to see exactly which groups were called on. 

Reminder that the downloads were as follows and this is how the folders should be names, the folders were downloaded in this order as long as you reverse pasted into the chunk above correctly:
1. Reptiles
2. Mammals
3. Fungi
4. Arthropods
5. Plants
6. Amphibia
7. Aves
8. Fish
9. Inverts

Rename the .zip files in the folders to the correct group as written above in the list.

After renaming, extract the zip files. The folder "October2024/Raw" should now have 18 folders (one zip and unzipped for each group, as named above).

Congrats! You've completed step 1 of the process. Time to move on to step 2. 